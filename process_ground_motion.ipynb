{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6645807-b59d-4afc-83be-68786443213a",
   "metadata": {},
   "source": [
    "# Clustering analysis of ground motion time series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cd68a0-1a77-4807-92d3-434d0c5f3d58",
   "metadata": {},
   "source": [
    "In this notebook, I will analyse a test area of Norway from the Norwat InSAR ground motion data.\n",
    "\n",
    "This will include timeseries for each of the points. The idea is that timeseries patterns can be grouped together, so we want to identify how this classification works. \n",
    "Following the tutorial from [here](https://www.kaggle.com/izzettunc/introduction-to-time-series-clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f92f27-26c8-4007-8491-f220ba1bc279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Native libraries\n",
    "import os\n",
    "import math\n",
    "# Essential Libraries\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ipywidgets import *\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Algorithms\n",
    "from minisom import MiniSom\n",
    "from tslearn.barycenters import dtw_barycenter_averaging\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ac0922-4e9c-44ae-a729-460072fd804e",
   "metadata": {},
   "source": [
    "Select a test area to download data from - currently in the `./tmp/` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb4fec2-0310-45a5-96c6-e584984b6333",
   "metadata": {},
   "outputs": [],
   "source": [
    "gm_csv = pd.read_csv('./tmp/160-IW1-414-s1-asc1-v2020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae87cc7-65d2-417f-9957-cac52980d87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove whitespaces from column names \n",
    "gm_csv.rename(columns=lambda x: x.strip(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d34fa9d-64b0-4062-b746-1c4d56e5a7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transposer - rowes are columns and vice versa\n",
    "gm_csv_t = gm_csv.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e81e29-2d13-472a-9374-e16257e5f8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the 'pid' as the column name\n",
    "gm_csv_t.rename(columns=gm_csv_t.iloc[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe057468-312b-4514-9de1-fd744f93a078",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all rows which are not dates - first date is on entry #21\n",
    "gm_csv_t_dates= gm_csv_t.iloc[21: , :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8050fed9-8b04-484f-b55f-2afb925ce462",
   "metadata": {},
   "outputs": [],
   "source": [
    "gm_csv_t_dates.columns = gm_csv_t_dates.columns.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b562f1-fb22-410a-b281-92158e92bb14",
   "metadata": {},
   "source": [
    "Check for outliers or anomalous time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a45039-17b6-46c2-aba5-c1a58fb198c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select rows that have values above a certain threshold\n",
    "gm_csv_t_dates[gm_csv_t_dates.columns[(gm_csv_t_dates>4000).any()]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664fa25f-42ee-413b-acd6-6a7463d847f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### WIDGET to visualise the timeseries\n",
    "plt.rcParams['figure.figsize'] = [7,4]\n",
    "\n",
    "column_name = gm_csv_t_dates.columns\n",
    "\n",
    "def plot_data(column_number):\n",
    "    plt.plot(gm_csv_t_dates.iloc[:,column_number].values)\n",
    "    \n",
    "interact(plot_data, column_number=(0,len(column_name)-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a87ffb5-936c-4945-b34e-123c9fda6271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert each of the columns into a pandas series \n",
    "# for now let's assume that the data has no gaps and that all columns are the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab032f69-4c57-47e5-a67e-fe843025e993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for nan values and for columns of different length\n",
    "all_column_lengths = []\n",
    "columns_with_nan_values = []\n",
    "for i in range(len(gm_csv_t_dates)): \n",
    "    all_column_lengths.append(len(gm_csv_t_dates.iloc[:, i]))\n",
    "    if gm_csv_t_dates[gm_csv_t_dates.columns[i]].isnull().values.any() == True:\n",
    "        columns_with_nan_values.append(gm_csv_t_dates.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ea81b2-aa3d-436b-9022-572455100f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the length of all columns is the same\n",
    "np.unique(np.array(all_column_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846baaa6-3476-4c76-ab0c-115f69d49516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are any columns with Nan values\n",
    "columns_with_nan_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc27ab39-e66a-469d-9e4a-20d5ad2b7c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to make a copy of the dataframe so that I don't mess it up\n",
    "gm_copy = gm_csv_t_dates.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713c7aaf-e004-42af-9181-6d0d9eb9922d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the orginal copy of the dataframe - without scaling\n",
    "gm_copy_of_copy = gm_copy.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb751b07-e69e-4bdf-b0dd-6d2266d7ab2c",
   "metadata": {},
   "source": [
    "#### CHANGE TO SERIES!!!! \n",
    "this is better for the classification tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13513007-cc9a-4e70-9cca-9d8b112f4867",
   "metadata": {},
   "outputs": [],
   "source": [
    "mySeries = []\n",
    "for i in range(len(gm_copy.columns)):\n",
    "    df = pd.DataFrame(gm_copy.iloc[:,i])\n",
    "    mySeries.append(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e363fb14-e86c-4c3a-a050-16bfaeeb6f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(gm_copy.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2184b7-4b36-41eb-9372-cd55be895038",
   "metadata": {},
   "outputs": [],
   "source": [
    "mySeries[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d70328-edc4-4d25-8dd2-093771a2afd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to normalise the timeseries columns before doing any clustering\n",
    "\n",
    "for i in range(len(mySeries)):\n",
    "    scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "    mySeries[i] = MinMaxScaler(feature_range=(-1,1)).fit_transform(mySeries[i])\n",
    "    mySeries[i]= mySeries[i].reshape(len(mySeries[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca74d6f-333d-4d3a-abb0-0010656da895",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"max: \"+str(max(mySeries[0]))+\"\\tmin: \"+str(min(mySeries[0])))\n",
    "print(mySeries[0][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d3ad18-54f3-4dcd-b72f-590762422a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the size of the grid. For example: som_x = som_y = 2 would give 4 clusters\n",
    "som_x = som_y = math.ceil(math.sqrt(math.sqrt(len(mySeries))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f804466d-6888-49b7-a710-093642c69d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATTENTION: these parameters have not been optimised!!\n",
    "som = MiniSom(som_x, som_y,len(mySeries[0]), sigma=0.3, learning_rate = 0.1)\n",
    "\n",
    "som.random_weights_init(mySeries)\n",
    "som.train(mySeries, 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62ccdc1-dcd3-460f-bc55-ee742ee73ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Little handy function to plot series\n",
    "def plot_som_series_averaged_center(som_x, som_y, win_map):\n",
    "    fig, axs = plt.subplots(som_x,som_y,figsize=(25,25))\n",
    "    fig.suptitle('Clusters')\n",
    "    for x in range(som_x):\n",
    "        for y in range(som_y):\n",
    "            cluster = (x,y)\n",
    "            if cluster in win_map.keys():\n",
    "                for series in win_map[cluster]:\n",
    "                    axs[cluster].plot(series,c=\"gray\",alpha=0.5) \n",
    "                axs[cluster].plot(np.average(np.vstack(win_map[cluster]),axis=0),c=\"red\")\n",
    "            cluster_number = x*som_y+y+1\n",
    "            axs[cluster].set_title(f\"Cluster {cluster_number}\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5016e824-6754-4616-bcda-f9d191977fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "win_map = som.win_map(mySeries)\n",
    "# Returns the mapping of the winner nodes and inputs\n",
    "\n",
    "plot_som_series_averaged_center(som_x, som_y, win_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0823b87-2fdc-460e-851f-60cc9da89016",
   "metadata": {},
   "outputs": [],
   "source": [
    "win_map = som.win_map(mySeries)\n",
    "\n",
    "#plot_som_series_dba_center(som_x, som_y, win_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fa3e29-63fb-4c8a-be69-83c1c15ad662",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_c = []\n",
    "cluster_n = []\n",
    "for x in range(som_x):\n",
    "    for y in range(som_y):\n",
    "        cluster = (x,y)\n",
    "        if cluster in win_map.keys():\n",
    "            cluster_c.append(len(win_map[cluster]))\n",
    "        else:\n",
    "            cluster_c.append(0)\n",
    "        cluster_number = x*som_y+y+1\n",
    "        cluster_n.append(f\"Cluster {cluster_number}\")\n",
    "\n",
    "plt.figure(figsize=(25,5))\n",
    "plt.title(\"Cluster Distribution for SOM\")\n",
    "plt.bar(cluster_n,cluster_c)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91096121-057c-4558-be20-59659a2b15ac",
   "metadata": {},
   "source": [
    "#### K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b072596d-aa09-454d-913e-f7157d607b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cluster_count = math.ceil(math.sqrt(len(mySeries))) \n",
    "# A good rule of thumb is choosing k as the square root of the number of points in the training data set in kNN\n",
    "\n",
    "km = TimeSeriesKMeans(n_clusters=cluster_count, metric=\"dtw\")\n",
    "\n",
    "labels = km.fit_predict(mySeries)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a10527-8720-41d1-a47c-4119a716310d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_count = math.ceil(math.sqrt(cluster_count))\n",
    "\n",
    "fig, axs = plt.subplots(plot_count,plot_count,figsize=(25,25))\n",
    "fig.suptitle('Clusters')\n",
    "row_i=0\n",
    "column_j=0\n",
    "# For each label there is,\n",
    "# plots every series with that label\n",
    "for label in set(labels):\n",
    "    cluster = []\n",
    "    for i in range(len(labels)):\n",
    "            if(labels[i]==label):\n",
    "                axs[row_i, column_j].plot(mySeries[i],c=\"gray\",alpha=0.4)\n",
    "                cluster.append(mySeries[i])\n",
    "    if len(cluster) > 0:\n",
    "        axs[row_i, column_j].plot(np.average(np.vstack(cluster),axis=0),c=\"red\")\n",
    "    axs[row_i, column_j].set_title(\"Cluster \"+str(row_i*som_y+column_j))\n",
    "    column_j+=1\n",
    "    if column_j%plot_count == 0:\n",
    "        row_i+=1\n",
    "        column_j=0\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709513f5-5d3f-407d-b442-7d2bfe612263",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
